#!/usr/bin/env python3
"""
æ¯æ—¥ç§‘æŠ€èµ„è®¯æŠ“å–ä¸ŽæŽ¨é€è„šæœ¬
æŠ“å–è¿‡åŽ»24å°æ—¶ä¸»æµç§‘æŠ€åª’ä½“æ–°é—»ï¼Œé€šè¿‡Serveré…±å‘é€åˆ°å¾®ä¿¡
"""

import os
import requests
import json
from datetime import datetime, timedelta
import time
from bs4 import BeautifulSoup

class TechNewsCollector:
    def __init__(self):
        self.server_chan_key = os.getenv('SERVER_CHAN_KEY')
        self.twenty_four_hours_ago = datetime.now() - timedelta(hours=24)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.all_news = []
    
    def fetch_techcrunch(self):
        """æŠ“å–TechCrunchæ–°é—»ï¼ˆé€šè¿‡APIï¼‰[citation:2]"""
        try:
            api_url = "https://techcrunch.com/wp-json/tc/v1/magazine?page=1&_embed=true"
            response = requests.get(api_url, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                articles = response.json()
                for article in articles[:5]:  # å–å‰5æ¡
                    # è§£æžå‘å¸ƒæ—¥æœŸï¼ˆæ ¹æ®å®žé™…APIå“åº”è°ƒæ•´ï¼‰
                    title = article.get('title', {}).get('rendered', '')
                    link = article.get('link', '')
                    
                    self.all_news.append({
                        'title': title[:100] + '...' if len(title) > 100 else title,
                        'link': link,
                        'source': 'TechCrunch',
                        'time': datetime.now().strftime('%Y-%m-%d')
                    })
        except Exception as e:
            print(f"TechCrunchæŠ“å–å¤±è´¥: {e}")
    
    def fetch_sina_tech(self):
        """æŠ“å–æ–°æµªç§‘æŠ€æ–°é—»ï¼ˆç¤ºä¾‹ï¼‰[citation:6]"""
        try:
            url = "https://finance.sina.com.cn/tech/"
            response = requests.get(url, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                response.encoding = 'utf-8'
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # æŸ¥æ‰¾æ–°é—»åˆ—è¡¨ï¼ˆæ ¹æ®å®žé™…é¡µé¢ç»“æž„è°ƒæ•´ï¼‰
                news_items = soup.find_all('li', class_=False)[:10]
                
                for item in news_items:
                    link_tag = item.find('a')
                    if link_tag:
                        title = link_tag.get_text().strip()
                        link = link_tag.get('href')
                        if link and not link.startswith('http'):
                            link = 'https:' + link
                        
                        self.all_news.append({
                            'title': title[:80] + '...' if len(title) > 80 else title,
                            'link': link,
                            'source': 'æ–°æµªç§‘æŠ€',
                            'time': datetime.now().strftime('%H:%M')
                        })
        except Exception as e:
            print(f"æ–°æµªç§‘æŠ€æŠ“å–å¤±è´¥: {e}")
    
    def fetch_hackernews(self):
        """æŠ“å–Hacker Newsçƒ­é—¨æ–°é—»"""
        try:
            # èŽ·å–çƒ­é—¨æ•…äº‹ID
            top_url = "https://hacker-news.firebaseio.com/v0/topstories.json"
            response = requests.get(top_url, timeout=10)
            
            if response.status_code == 200:
                story_ids = response.json()[:8]
                
                for story_id in story_ids[:5]:  # åªèŽ·å–å‰5æ¡è¯¦æƒ…
                    story_url = f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
                    story_resp = requests.get(story_url, timeout=5)
                    
                    if story_resp.status_code == 200:
                        story = story_resp.json()
                        # æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦åœ¨24å°æ—¶å†…
                        if 'time' in story:
                            story_time = datetime.fromtimestamp(story['time'])
                            if story_time > self.twenty_four_hours_ago:
                                self.all_news.append({
                                    'title': story.get('title', ''),
                                    'link': story.get('url', f'https://news.ycombinator.com/item?id={story_id}'),
                                    'source': 'Hacker News',
                                    'score': story.get('score', 0),
                                    'time': story_time.strftime('%Y-%m-%d %H:%M')
                                })
                    time.sleep(0.2)  # ç¤¼è²Œå»¶è¿Ÿ
                    
        except Exception as e:
            print(f"Hacker NewsæŠ“å–å¤±è´¥: {e}")
    
    def format_message(self):
        """æ ¼å¼åŒ–æŽ¨é€æ¶ˆæ¯"""
        if not self.all_news:
            return "ä»Šæ—¥æš‚æ— ç§‘æŠ€èµ„è®¯", "ç§‘æŠ€èµ„è®¯æ—¥æŠ¥ï¼ˆç©ºï¼‰"
        
        # æŒ‰æ¥æºåˆ†ç»„
        news_by_source = {}
        for item in self.all_news:
            source = item.get('source', 'å…¶ä»–')
            if source not in news_by_source:
                news_by_source[source] = []
            news_by_source[source].append(item)
        
        # æž„å»ºMarkdownæ¶ˆæ¯
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M')
        message = f"## ðŸš€ ç§‘æŠ€èµ„è®¯æ—¥æŠ¥ ({current_time})\n\n"
        message += f"è¿‡åŽ»24å°æ—¶å…±æŠ“å– **{len(self.all_news)}** æ¡èµ„è®¯\n\n"
        
        for source, items in news_by_source.items():
            message += f"### ðŸ“° {source}\n"
            for i, item in enumerate(items[:3], 1):  # æ¯ä¸ªæ¥æºæœ€å¤š3æ¡
                title = item['title']
                url = item['link']
                
                # æ·»åŠ é¢å¤–ä¿¡æ¯
                extra = ""
                if 'score' in item and item['score'] > 0:
                    extra = f" | ðŸ‘ {item['score']}"
                
                message += f"{i}. **{title}**{extra}\n"
                message += f"   ðŸ”— {url}\n\n"
        
        message += "\n---\n"
        message += "ðŸ“Š æ•°æ®æ¥æº: TechCrunchã€æ–°æµªç§‘æŠ€ã€Hacker Newsç­‰\n"
        message += "â° ä¸‹æ¬¡æ›´æ–°: æ˜Žæ—¥ 08:00 (åŒ—äº¬æ—¶é—´)"
        
        title = f"ç§‘æŠ€èµ„è®¯æ—¥æŠ¥ ({datetime.now().strftime('%m-%d')})"
        return message, title
    
    def send_to_wechat(self, message, title):
        """é€šè¿‡Serveré…±å‘é€åˆ°å¾®ä¿¡[citation:5]"""
        if not self.server_chan_key:
            print("æœªè®¾ç½®Serveré…±å¯†é’¥ï¼Œè·³è¿‡æŽ¨é€")
            return False
        
        # Serveré…±Turboç‰ˆAPI (æŽ¨è)
        url = f"https://sctapi.ftqq.com/{self.server_chan_key}.send"
        
        data = {
            'title': title,
            'desp': message
        }
        
        try:
            response = requests.post(url, data=data, timeout=10)
            result = response.json()
            
            if result.get('code') == 0:
                print(f"âœ… å¾®ä¿¡æŽ¨é€æˆåŠŸï¼æ¶ˆæ¯ID: {result.get('data', {}).get('pushid')}")
                return True
            else:
                print(f"âŒ æŽ¨é€å¤±è´¥: {result.get('message')}")
                return False
        except Exception as e:
            print(f"âŒ æŽ¨é€è¯·æ±‚å¤±è´¥: {e}")
            return False
    
    def run(self):
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        print("=" * 60)
        print(f"å¼€å§‹æ‰§è¡Œç§‘æŠ€èµ„è®¯æŠ“å– - {datetime.now()}")
        print("=" * 60)
        
        # é¡ºåºæŠ“å–å„æ¥æº
        print("\n1. æŠ“å–TechCrunch...")
        self.fetch_techcrunch()
        time.sleep(1)
        
        print("2. æŠ“å–æ–°æµªç§‘æŠ€...")
        self.fetch_sina_tech()
        time.sleep(1)
        
        print("3. æŠ“å–Hacker News...")
        self.fetch_hackernews()
        
        print(f"\nâœ… æŠ“å–å®Œæˆï¼å…±èŽ·å¾— {len(self.all_news)} æ¡èµ„è®¯")
        
        # æ ¼å¼åŒ–å¹¶å‘é€
        message, title = self.format_message()
        
        print("\n" + "=" * 60)
        print("ç”Ÿæˆçš„æ¶ˆæ¯æ‘˜è¦ï¼š")
        print("=" * 60)
        print(message[:500] + "..." if len(message) > 500 else message)
        
        if self.server_chan_key:
            print("\næ­£åœ¨å‘é€åˆ°å¾®ä¿¡...")
            self.send_to_wechat(message, title)
        else:
            print("\nâš ï¸ æœªé…ç½®SERVER_CHAN_KEYï¼Œè·³è¿‡æŽ¨é€æ­¥éª¤")
            print("å¦‚éœ€æŽ¨é€ï¼Œè¯·åœ¨GitHubä»“åº“Settings â†’ Secretsä¸­è®¾ç½®")
        
        # ä¿å­˜ç»“æžœåˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        with open('news_result.json', 'w', encoding='utf-8') as f:
            json.dump(self.all_news, f, ensure_ascii=False, indent=2)
        
        return len(self.all_news)

if __name__ == "__main__":
    collector = TechNewsCollector()
    news_count = collector.run()
    exit(0 if news_count > 0 else 1)
